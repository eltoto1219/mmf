dataset_config:
  masked_gqa:
    data_dir: ${env.data_dir}/datasets
    depth_first: false
    fast_read: false
    use_images: false
    use_features: true
    add_answer: true
    return_features_info: true
    use_image_feature_masks: false
    max_features: 36
    use_ocr: false
    use_ocr_info: false
    features:
      train:
      - gqa/defaults/features/gqa.lmdb
      val:
      - gqa/defaults/features/gqa.lmdb
      test:
      - gqa/defaults/features/gqa.lmdb
    annotations:
      train:
      - gqa/defaults/annotations/train_balanced_questions.npy
      val:
      - gqa/defaults/annotations/val_balanced_questions.npy
      test:
      - gqa/defaults/annotations/test_balanced_questions.npy
    processors:
      bbox_processor:
        type: bbox
        params:
          max_length: 36
      text_processor:
        type: bert_tokenizer
        params:
            tokenizer_config:
              type: bert-base-uncased
              params:
                do_lower_case: true
            mask_probability: 0.15
            max_seq_length: 20
      attribute_processor:
        type: vocab
        params:
          max_length: 1
          vocab:
            type: random
            vocab_file: vocabs/vocabulary_100k.txt
      name_processor:
        type: vocab
        params:
          max_length: 1
          vocab:
            type: random
            vocab_file: vocabs/vocabulary_100k.txt
      answer_processor:
        type: vqa_answer
        params:
          num_answers: 10
          vocab_file: gqa/defaults/vocabs/answers_gqa.txt
          preprocessor:
            type: simple_word
            params: {}
        masked_token_processor:
          type: masked_token
          params:
            tokenizer_config:
              type: bert-base-uncased
              params:
                do_lower_case: true
            mask_probability: 0.15
            max_seq_length: 20

model_config:
  lxmert:
    training_head_type: pretraining

optimizer:
  type: adam_w
  params:
    lr: 1e-4
    eps: 1e-8

tiraining:
  seed: 9595
  batch_size: 64
  lr_scheduler: false
  find_unused_parameters: true
  use_warmup: true
  warmup_factor: 0.05
  warmup_iterations: 1000
  max_epochs: 20
  max_updates: null
