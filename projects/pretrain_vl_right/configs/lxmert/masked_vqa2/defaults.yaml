<<<<<<< HEAD
dataset_config:
  masked_vqa2:
=======
model_config:
  lxmert:
    training_head_type: pretraining
    num_labels: 3129
    

dataset_config:
 masked_vqa2:
    processors:
      text_processor:
        type: bert_tokenizer
        params:
          tokenizer_config:
            type: bert-base-uncased
            params:
              do_lower_case: true
          mask_probability: 0
          max_seq_length: 128
      answer_processor:
        type: vqa_answer
        params:
            num_answers: 10
            vocab_file: vqa2/defaults/extras/vocabs/answers_vqa.txt
            preprocessor:
              type: simple_word
              params: {}
>>>>>>> Add files via upload
    use_images: false
    add_answer: true
    use_features: true
    features:
      train:
      - coco/defaults/features/trainval2014.lmdb
<<<<<<< HEAD
=======
      - coco/defaults/features/trainval2014.lmdb
>>>>>>> Add files via upload
    annotations:
      train:
      - vqa2/defaults/annotations/imdb_train2014.npy
      - vqa2/defaults/annotations/imdb_val2014.npy
    return_features_info: true
    use_image_feature_masks: true
<<<<<<< HEAD
    processors:
        masked_token_processor:
            type: masked_token
            params:
              tokenizer_config:
                type: bert-base-uncased
                params:
                    do_lower_case: true
              mask_probability: 0.15
              max_seq_length: 128
        text_processor:
            type: bert_tokenizer
            params:
              tokenizer_config:
                type: bert-base-uncased
                params:
                    do_lower_case: true
              mask_probability: 0
              max_seq_length: 128
        answer_processor:
            type: vqa_answer
            params:
                num_answers: 10
                vocab_file: vqa2/defaults/extras/vocabs/answers_vqa.txt
                preprocessor:
                  type: simple_word
                  params: {}
=======
>>>>>>> Add files via upload

optimizer:
  type: adam_w
  params:
    lr: 1e-4
    eps: 1e-8

scheduler:
  type: warmup_linear
  params:
    num_warmup_steps: 1000
    num_training_steps: 11000

training:
<<<<<<< HEAD
  seed: 9595
  batch_size: 256
=======
  batch_size: 16
>>>>>>> Add files via upload
  lr_scheduler: true
  # Don't forget to update schedule_attributes if you update this
  max_updates: null
  max_epochs: 20
  find_unused_parameters: true

